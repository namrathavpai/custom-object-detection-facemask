{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KWQAV5uA9R2k"
   },
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vFSX5wgi9p17"
   },
   "outputs": [],
   "source": [
    "#paths for the variable \n",
    "WORKSPACE_PATH = os.path.join('Tensorflow','workspace')\n",
    "SCRIPTS_PATH_MID =  os.path.join('Tensorflow','scripts')\n",
    "SCRIPTS_PATH =  os.path.join(SCRIPTS_PATH_MID,'preprocessing')\n",
    "APIMODEL_PATH =   os.path.join('Tensorflow','models')\n",
    "ANNOTATION_PATH = os.path.join(WORKSPACE_PATH,'annotations')\n",
    "IMAGE_PATH = os.path.join(WORKSPACE_PATH,'images')\n",
    "MODEL_PATH = os.path.join(WORKSPACE_PATH,'models')\n",
    "PRETRAINED_MODEL_PATH = os.path.join(WORKSPACE_PATH,'pre-trained-models')\n",
    "CHECKPOINT_PATH = os.path.join(MODEL_PATH,'my_ssd_mobnet')\n",
    "IMAGE_TRAIN=os.path.join(IMAGE_PATH , 'train')\n",
    "IMAGE_TEST=os.path.join(IMAGE_PATH , 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Fdytod2GcPpa"
   },
   "outputs": [],
   "source": [
    "# paths for the files\n",
    "TF_RECORD=os.path.join(SCRIPTS_PATH,'generate_tfrecord.py')\n",
    "LABEL_MAP=os.path.join(ANNOTATION_PATH , 'label_map.pbtxt')\n",
    "TRAIN_RECORD=os.path.join(ANNOTATION_PATH , 'train.record')\n",
    "TEST_RECORD=os.path.join(ANNOTATION_PATH , 'test.record')\n",
    "PIPELINE=os.path.join(PRETRAINED_MODEL_PATH, \"ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8\", 'pipeline.config')\n",
    "CUSTOM_PIPELINE=os.path.join(CHECKPOINT_PATH,'pipeline.config')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating folder struture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OQAW5f559vqw"
   },
   "outputs": [],
   "source": [
    "path_folder=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "NRpWTyZzBM0Q"
   },
   "outputs": [],
   "source": [
    "!mkdir Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "P-3v_cEA-UUK"
   },
   "outputs": [],
   "source": [
    "path_folder.append(WORKSPACE_PATH)\n",
    "path_folder.append(SCRIPTS_PATH_MID)\n",
    "path_folder.append(SCRIPTS_PATH)\n",
    "path_folder.append(APIMODEL_PATH)\n",
    "path_folder.append(ANNOTATION_PATH)\n",
    "path_folder.append(IMAGE_PATH)\n",
    "path_folder.append(MODEL_PATH)\n",
    "path_folder.append(PRETRAINED_MODEL_PATH)\n",
    "path_folder.append(CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "1_qqqw-1L2uB",
    "outputId": "aaf6d910-da48-441f-f1e1-3002e0972345"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Tensorflow/scripts/preprocessing'"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_folder[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "X3MHkvT3-51B"
   },
   "outputs": [],
   "source": [
    "for folders in path_folder:\n",
    "  !mkdir -p $folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download Tensorflow Object Detection Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WGcipmf_BFrQ",
    "outputId": "8501d902-7e04-4776-c13e-8a5eb4f15523",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Tensorflow/models'...\n",
      "remote: Enumerating objects: 58183, done.\u001b[K\n",
      "remote: Counting objects: 100% (515/515), done.\u001b[K\n",
      "remote: Compressing objects: 100% (270/270), done.\u001b[K\n",
      "remote: Total 58183 (delta 287), reused 449 (delta 240), pack-reused 57668\u001b[K\n",
      "Receiving objects: 100% (58183/58183), 573.14 MiB | 32.22 MiB/s, done.\n",
      "Resolving deltas: 100% (40282/40282), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/tensorflow/models $APIMODEL_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download Protobuf**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ooTP3FBD2nj",
    "outputId": "f8ff8a7c-56f5-4ce9-d286-167ac91204c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "# !pip install cloud-annotations==0.0.4\n",
    "# !pip install tf_slim\n",
    "# !pip install lvis\n",
    "# !pip install --no-deps tensorflowjs==1.4.0\n",
    "!apt-get install protobuf-compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ia2M5ypvELmC"
   },
   "outputs": [],
   "source": [
    "# !cd Tensorflow/models/research/ && cp object_detection/packages/tf2/setup.py . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jBKw7NL9FWhu",
    "outputId": "b3a907bc-c5cc-4900-8d97-032d214f3f08",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /content/Tensorflow/models/research\n",
      "Collecting avro-python3\n",
      "  Downloading https://files.pythonhosted.org/packages/cc/97/7a6970380ca8db9139a3cc0b0e3e0dd3e4bc584fb3644e1d06e71e1a55f0/avro-python3-1.10.2.tar.gz\n",
      "Collecting apache-beam\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/7f/342e6bf4bbdc55418c929b3281948070ef4ca83e198dc9135352c25799f9/apache_beam-2.29.0-cp37-cp37m-manylinux2010_x86_64.whl (9.6MB)\n",
      "\u001b[K     |████████████████████████████████| 9.6MB 14.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
      "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.23)\n",
      "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
      "Collecting tf-slim\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
      "\u001b[K     |████████████████████████████████| 358kB 40.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
      "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.2)\n",
      "Collecting lvis\n",
      "  Downloading https://files.pythonhosted.org/packages/72/b6/1992240ab48310b5360bfdd1d53163f43bb97d90dc5dc723c67d41c38e78/lvis-0.5.3-py3-none-any.whl\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.5)\n",
      "Collecting tf-models-official\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/08/81bbc275e8e9c6d1e03dd26daec3a67f45e6322804cbce3d51f93eae1961/tf_models_official-2.5.0-py2.py3-none-any.whl (1.6MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6MB 49.6MB/s \n",
      "\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n",
      "  Downloading https://files.pythonhosted.org/packages/08/f7/4c3fad73123a24d7394b6f40d1ec9c1cbf2e921cfea1797216ffd0a51fb1/hdfs-2.6.0-py3-none-any.whl\n",
      "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2018.9)\n",
      "Collecting fastavro<2,>=0.21.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/d1/8f5c8611026f0ddcd86a8e2f965998e0c159af980c31efba72342c69f3e4/fastavro-1.4.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3MB 44.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
      "Requirement already satisfied: pyarrow<4.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.0.0)\n",
      "Requirement already satisfied: oauth2client<5,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (4.1.3)\n",
      "Requirement already satisfied: protobuf<4,>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.12.4)\n",
      "Collecting future<1.0.0,>=0.18.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
      "\u001b[K     |████████████████████████████████| 829kB 47.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: httplib2<0.18.0,>=0.8 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (0.17.4)\n",
      "Collecting requests<3.0.0,>=2.24.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/c1/24814557f1d22c56d50280771a17307e6bf87b70727d975fd6b2ce6b014a/requests-2.25.1-py2.py3-none-any.whl (61kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 9.2MB/s \n",
      "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/11/345f3173809cea7f1a193bfbf02403fff250a3360e0e118a1630985e547d/dill-0.3.1.1.tar.gz (151kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 60.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy<1.21.0,>=1.14.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2.8.1)\n",
      "Requirement already satisfied: typing-extensions<3.8.0,>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.7.4.3)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.11.4)\n",
      "Requirement already satisfied: grpcio<2,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.32.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (2.4.7)\n",
      "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf-slim->object-detection==0.1) (0.12.0)\n",
      "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools->object-detection==0.1) (56.1.0)\n",
      "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
      "Collecting pyyaml>=5.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
      "\u001b[K     |████████████████████████████████| 645kB 45.6MB/s \n",
      "\u001b[?25hCollecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2MB 49.5MB/s \n",
      "\u001b[?25hCollecting tensorflow-addons\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/4b/e893d194e626c24b3df2253066aa418f46a432fdb68250cde14bf9bb0700/tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679kB)\n",
      "\u001b[K     |████████████████████████████████| 686kB 46.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (4.0.1)\n",
      "Collecting py-cpuinfo>=3.3.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/ba/77120e44cbe9719152415b97d5bfb29f4053ee987d6cb63f55ce7d50fadc/py-cpuinfo-8.0.0.tar.gz (99kB)\n",
      "\u001b[K     |████████████████████████████████| 102kB 15.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (0.12.0)\n",
      "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (5.4.8)\n",
      "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.5.12)\n",
      "Collecting tensorflow>=2.5.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/fd/993aa1333eb54d9f000863fe8ec61e41d12eb833dea51484c76c038718b5/tensorflow-2.5.0-cp37-cp37m-manylinux2010_x86_64.whl (454.3MB)\n",
      "\u001b[K     |████████████████████████████████| 454.3MB 37kB/s \n",
      "\u001b[?25hCollecting sacrebleu\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/57/0c7ca4e31a126189dab99c19951910bd081dea5bbd25f24b77107750eae7/sacrebleu-1.5.1-py3-none-any.whl (54kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 10.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (0.4.0)\n",
      "Collecting opencv-python-headless\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/84/72ec52fbac4775c2a5bf0ee5573c922a0cac35eb841907edf56493a5e313/opencv_python_headless-4.5.2.52-cp37-cp37m-manylinux2014_x86_64.whl (38.2MB)\n",
      "\u001b[K     |████████████████████████████████| 38.2MB 77kB/s \n",
      "\u001b[?25hRequirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.12.8)\n",
      "Collecting tensorflow-model-optimization>=0.4.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/38/4fd48ea1bfcb0b6e36d949025200426fe9c3a8bfae029f0973d85518fa5a/tensorflow_model_optimization-0.5.0-py2.py3-none-any.whl (172kB)\n",
      "\u001b[K     |████████████████████████████████| 174kB 58.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: google-cloud-bigquery>=0.31.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.21.0)\n",
      "Collecting seqeval\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 8.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.2.8)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (4.7.2)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (1.24.3)\n",
      "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official->object-detection==0.1) (2.7.1)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (21.2.0)\n",
      "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (0.1.6)\n",
      "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (0.30.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (4.41.1)\n",
      "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (2.3)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (5.1.2)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (5.0.2)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.3.0)\n",
      "Collecting h5py~=3.1.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/74/9eae2bedd8201ab464308f42c601a12d79727a1c87f0c867fdefb212c6cf/h5py-3.1.0-cp37-cp37m-manylinux1_x86_64.whl (4.0MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0MB 16.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.12)\n",
      "Collecting tensorboard~=2.5\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/f5/7feea02a3fb54d5db827ac4b822a7ba8933826b36de21880518250b8733a/tensorboard-2.5.0-py3-none-any.whl (6.0MB)\n",
      "\u001b[K     |████████████████████████████████| 6.0MB 41.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.12.1)\n",
      "Collecting keras-nightly~=2.5.0.dev\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/e7/53bc896aa4e11a87aac10a625c676b3a3d57d1c8d9929e4809d31fa0b7d5/keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2MB 31.3MB/s \n",
      "\u001b[?25hCollecting gast==0.4.0\n",
      "  Downloading https://files.pythonhosted.org/packages/b6/48/583c032b79ae5b3daa02225a675aeb673e58d2cb698e78510feceb11958c/gast-0.4.0-py3-none-any.whl\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.6.3)\n",
      "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.36.2)\n",
      "Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/78/b27f73e923becc6e79e18fe112cf75e3200d1ee35b0dba8fa46181bce56c/tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462kB)\n",
      "\u001b[K     |████████████████████████████████| 471kB 54.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.1.2)\n",
      "Collecting portalocker==2.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.30.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (0.0.4)\n",
      "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.26.3)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (3.0.1)\n",
      "Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (0.4.1)\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.0.3)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official->object-detection==0.1) (0.22.2.post1)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets->tf-models-official->object-detection==0.1) (1.53.0)\n",
      "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tf-models-official->object-detection==0.1) (3.4.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official->object-detection==0.1) (1.3)\n",
      "Collecting cached-property; python_version < \"3.8\"\n",
      "  Downloading https://files.pythonhosted.org/packages/48/19/f2090f7dad41e225c7f2326e4cfe6fff49e57dedb5b53636c9551f86b069/cached_property-1.5.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (2.0.0)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/f9/802efd84988bffd9f644c03b6e66fde8e76c3aa33db4279ddd11c5d61f4b/tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9MB)\n",
      "\u001b[K     |████████████████████████████████| 4.9MB 45.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.4.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.3.4)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (4.2.2)\n",
      "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (20.9)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official->object-detection==0.1) (1.0.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (4.0.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.1.0)\n",
      "Building wheels for collected packages: object-detection, avro-python3, future, dill, py-cpuinfo, seqeval\n",
      "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for object-detection: filename=object_detection-0.1-cp37-none-any.whl size=1650082 sha256=2ce2836acb968ae70174746d5a5cab15005c343d0939e7ceeca15577bd658f05\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-hqz995uj/wheels/ac/8a/90/02d8042c0333b38a96341f55d93b379bb170f98b196de6b536\n",
      "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for avro-python3: filename=avro_python3-1.10.2-cp37-none-any.whl size=44011 sha256=9353984108f5576c78a0c2d3ae148e7c22aed5a9ecc2afec43218c1565bf66d7\n",
      "  Stored in directory: /root/.cache/pip/wheels/ee/ee/18/c466221ca6900e3efce2f4ea9c329288808679aecdcb2838d3\n",
      "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491058 sha256=fe992326688b32e56a90044351dc18cd34a5a013413df2390cf93709c0fe2c54\n",
      "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
      "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for dill: filename=dill-0.3.1.1-cp37-none-any.whl size=78532 sha256=7d3f1be8cc59e57b028aa9f16ae0daecbc4d6af0b39898d79e3e2aa8d2347716\n",
      "  Stored in directory: /root/.cache/pip/wheels/59/b1/91/f02e76c732915c4015ab4010f3015469866c1eb9b14058d8e7\n",
      "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-cp37-none-any.whl size=22245 sha256=5d6b3cffe0317fb01e85fba26098464794b3a6634181af898ff9fb822d113961\n",
      "  Stored in directory: /root/.cache/pip/wheels/2e/15/f5/aa2a056d223903b52cf4870134e3a01df0c723816835dd08db\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16172 sha256=8f4ad98dac31805a411331ca2179579b024b9470355bd97da317bfcd04f3b40c\n",
      "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
      "Successfully built object-detection avro-python3 future dill py-cpuinfo seqeval\n",
      "\u001b[31mERROR: tensorflow 2.5.0 has requirement grpcio~=1.34.0, but you'll have grpcio 1.32.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: multiprocess 0.70.11.1 has requirement dill>=0.3.3, but you'll have dill 0.3.1.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: apache-beam 2.29.0 has requirement avro-python3!=1.9.2,<1.10.0,>=1.8.1, but you'll have avro-python3 1.10.2 which is incompatible.\u001b[0m\n",
      "Installing collected packages: avro-python3, requests, hdfs, fastavro, future, dill, apache-beam, tf-slim, lvis, pyyaml, sentencepiece, tensorflow-addons, py-cpuinfo, cached-property, h5py, tensorboard-data-server, tensorboard, keras-nightly, gast, tensorflow-estimator, tensorflow, portalocker, sacrebleu, opencv-python-headless, tensorflow-model-optimization, seqeval, tf-models-official, object-detection\n",
      "  Found existing installation: requests 2.23.0\n",
      "    Uninstalling requests-2.23.0:\n",
      "      Successfully uninstalled requests-2.23.0\n",
      "  Found existing installation: future 0.16.0\n",
      "    Uninstalling future-0.16.0:\n",
      "      Successfully uninstalled future-0.16.0\n",
      "  Found existing installation: dill 0.3.3\n",
      "    Uninstalling dill-0.3.3:\n",
      "      Successfully uninstalled dill-0.3.3\n",
      "  Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "  Found existing installation: h5py 2.10.0\n",
      "    Uninstalling h5py-2.10.0:\n",
      "      Successfully uninstalled h5py-2.10.0\n",
      "  Found existing installation: tensorboard 2.4.1\n",
      "    Uninstalling tensorboard-2.4.1:\n",
      "      Successfully uninstalled tensorboard-2.4.1\n",
      "  Found existing installation: gast 0.3.3\n",
      "    Uninstalling gast-0.3.3:\n",
      "      Successfully uninstalled gast-0.3.3\n",
      "  Found existing installation: tensorflow-estimator 2.4.0\n",
      "    Uninstalling tensorflow-estimator-2.4.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
      "  Found existing installation: tensorflow 2.4.1\n",
      "    Uninstalling tensorflow-2.4.1:\n",
      "      Successfully uninstalled tensorflow-2.4.1\n",
      "Successfully installed apache-beam-2.29.0 avro-python3-1.10.2 cached-property-1.5.2 dill-0.3.1.1 fastavro-1.4.1 future-0.18.2 gast-0.4.0 h5py-3.1.0 hdfs-2.6.0 keras-nightly-2.5.0.dev2021032900 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.2.52 portalocker-2.0.0 py-cpuinfo-8.0.0 pyyaml-5.4.1 requests-2.25.1 sacrebleu-1.5.1 sentencepiece-0.1.95 seqeval-1.2.2 tensorboard-2.5.0 tensorboard-data-server-0.6.1 tensorflow-2.5.0 tensorflow-addons-0.13.0 tensorflow-estimator-2.5.0 tensorflow-model-optimization-0.5.0 tf-models-official-2.5.0 tf-slim-1.1.0\n"
     ]
    }
   ],
   "source": [
    "# !cd Tensorflow/models/research/ && python -m pip install . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cMp8J5yVCSuv",
    "outputId": "1030b559-d377-41f3-fd9f-7f0a6bebf378"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /content/Tensorflow/models/research\n",
      "Collecting avro-python3\n",
      "  Downloading https://files.pythonhosted.org/packages/cc/97/7a6970380ca8db9139a3cc0b0e3e0dd3e4bc584fb3644e1d06e71e1a55f0/avro-python3-1.10.2.tar.gz\n",
      "Collecting apache-beam\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/c9/395a9759dfbf9e87203a69c33b2e94f10d566d9391bddb6f99facafe64c3/apache_beam-2.30.0-cp37-cp37m-manylinux2010_x86_64.whl (9.6MB)\n",
      "\u001b[K     |████████████████████████████████| 9.6MB 7.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
      "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.23)\n",
      "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
      "Collecting tf-slim\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
      "\u001b[K     |████████████████████████████████| 358kB 47.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
      "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.2)\n",
      "Collecting lvis\n",
      "  Downloading https://files.pythonhosted.org/packages/72/b6/1992240ab48310b5360bfdd1d53163f43bb97d90dc5dc723c67d41c38e78/lvis-0.5.3-py3-none-any.whl\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.5)\n",
      "Collecting tf-models-official\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/08/81bbc275e8e9c6d1e03dd26daec3a67f45e6322804cbce3d51f93eae1961/tf_models_official-2.5.0-py2.py3-none-any.whl (1.6MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6MB 51.5MB/s \n",
      "\u001b[?25hCollecting fastavro<2,>=0.21.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/d1/8f5c8611026f0ddcd86a8e2f965998e0c159af980c31efba72342c69f3e4/fastavro-1.4.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3MB 45.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: httplib2<0.20.0,>=0.8 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (0.17.4)\n",
      "Collecting future<1.0.0,>=0.18.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
      "\u001b[K     |████████████████████████████████| 829kB 49.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy<1.21.0,>=1.14.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.19.5)\n",
      "Requirement already satisfied: oauth2client<5,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (4.1.3)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
      "Requirement already satisfied: pyarrow<4.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.0.0)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
      "Collecting dill<0.3.2,>=0.3.1.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/11/345f3173809cea7f1a193bfbf02403fff250a3360e0e118a1630985e547d/dill-0.3.1.1.tar.gz (151kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 55.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: grpcio<2,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.34.1)\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.11.4)\n",
      "Requirement already satisfied: typing-extensions<3.8.0,>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.7.4.3)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2.8.1)\n",
      "Collecting hdfs<3.0.0,>=2.1.0\n",
      "  Downloading https://files.pythonhosted.org/packages/08/f7/4c3fad73123a24d7394b6f40d1ec9c1cbf2e921cfea1797216ffd0a51fb1/hdfs-2.6.0-py3-none-any.whl\n",
      "Requirement already satisfied: protobuf<4,>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.12.4)\n",
      "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2018.9)\n",
      "Collecting requests<3.0.0,>=2.24.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/c1/24814557f1d22c56d50280771a17307e6bf87b70727d975fd6b2ce6b014a/requests-2.25.1-py2.py3-none-any.whl (61kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 10.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->object-detection==0.1) (2.4.7)\n",
      "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf-slim->object-detection==0.1) (0.12.0)\n",
      "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools->object-detection==0.1) (57.0.0)\n",
      "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
      "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (4.0.1)\n",
      "Collecting py-cpuinfo>=3.3.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/ba/77120e44cbe9719152415b97d5bfb29f4053ee987d6cb63f55ce7d50fadc/py-cpuinfo-8.0.0.tar.gz (99kB)\n",
      "\u001b[K     |████████████████████████████████| 102kB 14.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (5.4.8)\n",
      "Collecting sacrebleu\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/57/0c7ca4e31a126189dab99c19951910bd081dea5bbd25f24b77107750eae7/sacrebleu-1.5.1-py3-none-any.whl (54kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 10.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.5.12)\n",
      "Requirement already satisfied: tensorflow>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (2.5.0)\n",
      "Collecting pyyaml>=5.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
      "\u001b[K     |████████████████████████████████| 645kB 41.2MB/s \n",
      "\u001b[?25hCollecting opencv-python-headless\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/35/bfc76533f2274cd3da4e2cf255cd13ab9d7f6fc8990c06911e7f8fcc2130/opencv_python_headless-4.5.2.54-cp37-cp37m-manylinux2014_x86_64.whl (38.2MB)\n",
      "\u001b[K     |████████████████████████████████| 38.2MB 77kB/s \n",
      "\u001b[?25hRequirement already satisfied: google-cloud-bigquery>=0.31.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.21.0)\n",
      "Collecting tensorflow-model-optimization>=0.4.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/38/4fd48ea1bfcb0b6e36d949025200426fe9c3a8bfae029f0973d85518fa5a/tensorflow_model_optimization-0.5.0-py2.py3-none-any.whl (172kB)\n",
      "\u001b[K     |████████████████████████████████| 174kB 39.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (0.12.0)\n",
      "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official->object-detection==0.1) (1.12.8)\n",
      "Collecting tensorflow-addons\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/4b/e893d194e626c24b3df2253066aa418f46a432fdb68250cde14bf9bb0700/tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679kB)\n",
      "\u001b[K     |████████████████████████████████| 686kB 35.7MB/s \n",
      "\u001b[?25hCollecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2MB 36.9MB/s \n",
      "\u001b[?25hCollecting seqeval\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 8.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.2.8)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.4.8)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (4.7.2)\n",
      "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.0.4)\n",
      "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (2.3)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (4.41.1)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (21.2.0)\n",
      "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (5.1.3)\n",
      "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (0.1.6)\n",
      "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (1.0.0)\n",
      "Collecting portalocker==2.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (5.0.2)\n",
      "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.36.2)\n",
      "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.4.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.1.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.3.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.6.3)\n",
      "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (2.5.0)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (2.5.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.1.2)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.12)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.12.1)\n",
      "Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (0.4.1)\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.0.3)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (3.0.1)\n",
      "Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.30.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (0.0.4)\n",
      "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.26.3)\n",
      "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official->object-detection==0.1) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official->object-detection==0.1) (0.22.2.post1)\n",
      "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tf-models-official->object-detection==0.1) (3.4.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets->tf-models-official->object-detection==0.1) (1.53.0)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official->object-detection==0.1) (1.3)\n",
      "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.5.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.8.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.4.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.3.4)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (4.2.2)\n",
      "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (20.9)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official->object-detection==0.1) (1.0.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (4.0.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.1.0)\n",
      "Building wheels for collected packages: object-detection, avro-python3, future, dill, py-cpuinfo, seqeval\n",
      "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for object-detection: filename=object_detection-0.1-cp37-none-any.whl size=1652954 sha256=aba6b43b3706fa1a1232dd751796f6847bf7d1566cb9f7394d37a91a727dc1dd\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-q7m0k264/wheels/ac/8a/90/02d8042c0333b38a96341f55d93b379bb170f98b196de6b536\n",
      "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for avro-python3: filename=avro_python3-1.10.2-cp37-none-any.whl size=44011 sha256=aa4ba41dad0b45da2aacb69b1e759882668d22d4badf343b81a315ccc32e624a\n",
      "  Stored in directory: /root/.cache/pip/wheels/ee/ee/18/c466221ca6900e3efce2f4ea9c329288808679aecdcb2838d3\n",
      "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491070 sha256=7e5f79e32bc9d8eaa256d7c5c0f452ef1096391c94c0c6292d55ef65ee75e889\n",
      "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
      "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for dill: filename=dill-0.3.1.1-cp37-none-any.whl size=78545 sha256=c0acfc1bb48feff2bc6a1593017806f5ac9200875e1cb2c08e5f95965849246a\n",
      "  Stored in directory: /root/.cache/pip/wheels/59/b1/91/f02e76c732915c4015ab4010f3015469866c1eb9b14058d8e7\n",
      "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-cp37-none-any.whl size=22258 sha256=4da8dbd23c88739dd1748870e112900efbca655f34f9b60fafe1b6439e3aa597\n",
      "  Stored in directory: /root/.cache/pip/wheels/2e/15/f5/aa2a056d223903b52cf4870134e3a01df0c723816835dd08db\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16184 sha256=a2cb1a10f096aa87ded0bf29bda1d13b4a2f9e313ede8533e3b07b8234fefc9c\n",
      "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
      "Successfully built object-detection avro-python3 future dill py-cpuinfo seqeval\n",
      "\u001b[31mERROR: multiprocess 0.70.11.1 has requirement dill>=0.3.3, but you'll have dill 0.3.1.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: apache-beam 2.30.0 has requirement avro-python3!=1.9.2,<1.10.0,>=1.8.1, but you'll have avro-python3 1.10.2 which is incompatible.\u001b[0m\n",
      "Installing collected packages: avro-python3, fastavro, future, dill, requests, hdfs, apache-beam, tf-slim, lvis, py-cpuinfo, portalocker, sacrebleu, pyyaml, opencv-python-headless, tensorflow-model-optimization, tensorflow-addons, sentencepiece, seqeval, tf-models-official, object-detection\n",
      "  Found existing installation: future 0.16.0\n",
      "    Uninstalling future-0.16.0:\n",
      "      Successfully uninstalled future-0.16.0\n",
      "  Found existing installation: dill 0.3.3\n",
      "    Uninstalling dill-0.3.3:\n",
      "      Successfully uninstalled dill-0.3.3\n",
      "  Found existing installation: requests 2.23.0\n",
      "    Uninstalling requests-2.23.0:\n",
      "      Successfully uninstalled requests-2.23.0\n",
      "  Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed apache-beam-2.30.0 avro-python3-1.10.2 dill-0.3.1.1 fastavro-1.4.1 future-0.18.2 hdfs-2.6.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.2.54 portalocker-2.0.0 py-cpuinfo-8.0.0 pyyaml-5.4.1 requests-2.25.1 sacrebleu-1.5.1 sentencepiece-0.1.95 seqeval-1.2.2 tensorflow-addons-0.13.0 tensorflow-model-optimization-0.5.0 tf-models-official-2.5.0 tf-slim-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!cd Tensorflow/models/research/ && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cZgrit9SF8qB",
    "outputId": "8926d2e1-a588-465a-d6a9-0facb1407e45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-09 18:14:43.826155: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Running tests under Python 3.7.10: /usr/bin/python3\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "2021-06-09 18:14:45.798753: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-06-09 18:14:45.860381: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-09 18:14:45.861008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2021-06-09 18:14:45.861059: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-06-09 18:14:45.986120: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-06-09 18:14:45.986218: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-06-09 18:14:46.156164: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-06-09 18:14:46.175914: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-06-09 18:14:46.451383: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-06-09 18:14:46.477691: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-06-09 18:14:46.481604: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-06-09 18:14:46.481760: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-09 18:14:46.482503: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-09 18:14:46.485676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-06-09 18:14:46.486243: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-09 18:14:46.486798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2021-06-09 18:14:46.486887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-09 18:14:46.487471: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-09 18:14:46.487985: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-06-09 18:14:46.490399: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-06-09 18:14:50.830633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-06-09 18:14:50.830697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-06-09 18:14:50.830721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-06-09 18:14:50.830915: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-09 18:14:50.831569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-09 18:14:50.832151: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-09 18:14:50.832662: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2021-06-09 18:14:50.832708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13837 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "W0609 18:14:51.151468 139630267684736 model_builder.py:1085] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 5.6s\n",
      "I0609 18:14:51.383673 139630267684736 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 5.6s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.53s\n",
      "I0609 18:14:51.911767 139630267684736 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.53s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.24s\n",
      "I0609 18:14:52.151465 139630267684736 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.24s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.23s\n",
      "I0609 18:14:52.377641 139630267684736 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.23s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "W0609 18:14:52.379877 139630267684736 mobilenet_v2.py:296] `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9412608/9406464 [==============================] - 0s 0us/step\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.83s\n",
      "I0609 18:14:54.203712 139630267684736 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.83s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "I0609 18:14:54.204658 139630267684736 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
      "I0609 18:14:54.223976 139630267684736 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
      "I0609 18:14:54.237798 139630267684736 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
      "I0609 18:14:54.251581 139630267684736 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.09s\n",
      "I0609 18:14:54.340372 139630267684736 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.09s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.08s\n",
      "I0609 18:14:54.424156 139630267684736 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.08s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n",
      "I0609 18:14:54.519238 139630267684736 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n",
      "I0609 18:14:54.605136 139630267684736 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.08s\n",
      "I0609 18:14:54.688385 139630267684736 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.08s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.02s\n",
      "I0609 18:14:54.713396 139630267684736 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "I0609 18:14:54.870743 139630267684736 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
      "I0609 18:14:54.870888 139630267684736 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64\n",
      "I0609 18:14:54.870962 139630267684736 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 3\n",
      "I0609 18:14:54.872750 139630267684736 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0609 18:14:54.887928 139630267684736 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0609 18:14:54.888067 139630267684736 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0609 18:14:54.937893 139630267684736 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0609 18:14:54.938026 139630267684736 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0609 18:14:55.063359 139630267684736 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0609 18:14:55.063487 139630267684736 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0609 18:14:55.191593 139630267684736 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0609 18:14:55.191766 139630267684736 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0609 18:14:55.516774 139630267684736 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0609 18:14:55.516938 139630267684736 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0609 18:14:55.706791 139630267684736 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0609 18:14:55.706952 139630267684736 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0609 18:14:55.977526 139630267684736 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0609 18:14:55.977709 139630267684736 efficientnet_model.py:147] round_filter input=320 output=320\n",
      "I0609 18:14:56.038346 139630267684736 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
      "I0609 18:14:56.064075 139630267684736 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0609 18:14:56.109152 139630267684736 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
      "I0609 18:14:56.109275 139630267684736 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 88\n",
      "I0609 18:14:56.109347 139630267684736 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 4\n",
      "I0609 18:14:56.110807 139630267684736 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0609 18:14:56.124097 139630267684736 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0609 18:14:56.124197 139630267684736 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0609 18:14:56.223115 139630267684736 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0609 18:14:56.223238 139630267684736 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0609 18:14:56.419289 139630267684736 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0609 18:14:56.419450 139630267684736 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0609 18:14:56.620527 139630267684736 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0609 18:14:56.620699 139630267684736 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0609 18:14:56.892379 139630267684736 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0609 18:14:56.892588 139630267684736 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0609 18:14:57.165781 139630267684736 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0609 18:14:57.165947 139630267684736 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0609 18:14:57.498682 139630267684736 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0609 18:14:57.498857 139630267684736 efficientnet_model.py:147] round_filter input=320 output=320\n",
      "I0609 18:14:57.624541 139630267684736 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
      "I0609 18:14:57.649238 139630267684736 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0609 18:14:57.704165 139630267684736 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
      "I0609 18:14:57.704322 139630267684736 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 112\n",
      "I0609 18:14:57.704398 139630267684736 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 5\n",
      "I0609 18:14:57.705831 139630267684736 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0609 18:14:57.718185 139630267684736 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0609 18:14:57.718282 139630267684736 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0609 18:14:57.820963 139630267684736 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0609 18:14:57.821100 139630267684736 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0609 18:14:58.169242 139630267684736 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0609 18:14:58.169433 139630267684736 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0609 18:14:58.367249 139630267684736 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0609 18:14:58.367412 139630267684736 efficientnet_model.py:147] round_filter input=80 output=88\n",
      "I0609 18:14:58.629219 139630267684736 efficientnet_model.py:147] round_filter input=80 output=88\n",
      "I0609 18:14:58.629384 139630267684736 efficientnet_model.py:147] round_filter input=112 output=120\n",
      "I0609 18:14:58.885851 139630267684736 efficientnet_model.py:147] round_filter input=112 output=120\n",
      "I0609 18:14:58.886025 139630267684736 efficientnet_model.py:147] round_filter input=192 output=208\n",
      "I0609 18:14:59.224267 139630267684736 efficientnet_model.py:147] round_filter input=192 output=208\n",
      "I0609 18:14:59.224446 139630267684736 efficientnet_model.py:147] round_filter input=320 output=352\n",
      "I0609 18:14:59.355759 139630267684736 efficientnet_model.py:147] round_filter input=1280 output=1408\n",
      "I0609 18:14:59.381534 139630267684736 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0609 18:14:59.439486 139630267684736 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
      "I0609 18:14:59.439624 139630267684736 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 160\n",
      "I0609 18:14:59.439693 139630267684736 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 6\n",
      "I0609 18:14:59.441215 139630267684736 efficientnet_model.py:147] round_filter input=32 output=40\n",
      "I0609 18:14:59.453935 139630267684736 efficientnet_model.py:147] round_filter input=32 output=40\n",
      "I0609 18:14:59.454059 139630267684736 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0609 18:14:59.569117 139630267684736 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0609 18:14:59.569295 139630267684736 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0609 18:14:59.791248 139630267684736 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0609 18:14:59.791426 139630267684736 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0609 18:15:00.002764 139630267684736 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0609 18:15:00.002940 139630267684736 efficientnet_model.py:147] round_filter input=80 output=96\n",
      "I0609 18:15:00.327731 139630267684736 efficientnet_model.py:147] round_filter input=80 output=96\n",
      "I0609 18:15:00.327900 139630267684736 efficientnet_model.py:147] round_filter input=112 output=136\n",
      "I0609 18:15:00.653166 139630267684736 efficientnet_model.py:147] round_filter input=112 output=136\n",
      "I0609 18:15:00.653328 139630267684736 efficientnet_model.py:147] round_filter input=192 output=232\n",
      "I0609 18:15:01.043037 139630267684736 efficientnet_model.py:147] round_filter input=192 output=232\n",
      "I0609 18:15:01.043233 139630267684736 efficientnet_model.py:147] round_filter input=320 output=384\n",
      "I0609 18:15:01.323321 139630267684736 efficientnet_model.py:147] round_filter input=1280 output=1536\n",
      "I0609 18:15:01.349943 139630267684736 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0609 18:15:01.409040 139630267684736 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
      "I0609 18:15:01.409180 139630267684736 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 224\n",
      "I0609 18:15:01.409250 139630267684736 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n",
      "I0609 18:15:01.410697 139630267684736 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0609 18:15:01.423366 139630267684736 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0609 18:15:01.423472 139630267684736 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0609 18:15:01.530386 139630267684736 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0609 18:15:01.530503 139630267684736 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0609 18:15:01.792315 139630267684736 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0609 18:15:01.792490 139630267684736 efficientnet_model.py:147] round_filter input=40 output=56\n",
      "I0609 18:15:02.045288 139630267684736 efficientnet_model.py:147] round_filter input=40 output=56\n",
      "I0609 18:15:02.045454 139630267684736 efficientnet_model.py:147] round_filter input=80 output=112\n",
      "I0609 18:15:02.434867 139630267684736 efficientnet_model.py:147] round_filter input=80 output=112\n",
      "I0609 18:15:02.435054 139630267684736 efficientnet_model.py:147] round_filter input=112 output=160\n",
      "I0609 18:15:02.817184 139630267684736 efficientnet_model.py:147] round_filter input=112 output=160\n",
      "I0609 18:15:02.817348 139630267684736 efficientnet_model.py:147] round_filter input=192 output=272\n",
      "I0609 18:15:03.338237 139630267684736 efficientnet_model.py:147] round_filter input=192 output=272\n",
      "I0609 18:15:03.338408 139630267684736 efficientnet_model.py:147] round_filter input=320 output=448\n",
      "I0609 18:15:03.466289 139630267684736 efficientnet_model.py:147] round_filter input=1280 output=1792\n",
      "I0609 18:15:03.490497 139630267684736 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0609 18:15:03.570474 139630267684736 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
      "I0609 18:15:03.570604 139630267684736 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 288\n",
      "I0609 18:15:03.570671 139630267684736 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n",
      "I0609 18:15:03.572185 139630267684736 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0609 18:15:03.589074 139630267684736 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0609 18:15:03.589173 139630267684736 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0609 18:15:03.741528 139630267684736 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0609 18:15:03.741665 139630267684736 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0609 18:15:04.069816 139630267684736 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0609 18:15:04.069983 139630267684736 efficientnet_model.py:147] round_filter input=40 output=64\n",
      "I0609 18:15:04.578419 139630267684736 efficientnet_model.py:147] round_filter input=40 output=64\n",
      "I0609 18:15:04.578595 139630267684736 efficientnet_model.py:147] round_filter input=80 output=128\n",
      "I0609 18:15:05.032204 139630267684736 efficientnet_model.py:147] round_filter input=80 output=128\n",
      "I0609 18:15:05.032368 139630267684736 efficientnet_model.py:147] round_filter input=112 output=176\n",
      "I0609 18:15:05.486403 139630267684736 efficientnet_model.py:147] round_filter input=112 output=176\n",
      "I0609 18:15:05.486575 139630267684736 efficientnet_model.py:147] round_filter input=192 output=304\n",
      "I0609 18:15:06.073944 139630267684736 efficientnet_model.py:147] round_filter input=192 output=304\n",
      "I0609 18:15:06.074127 139630267684736 efficientnet_model.py:147] round_filter input=320 output=512\n",
      "I0609 18:15:06.272832 139630267684736 efficientnet_model.py:147] round_filter input=1280 output=2048\n",
      "I0609 18:15:06.306722 139630267684736 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0609 18:15:06.391533 139630267684736 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
      "I0609 18:15:06.391690 139630267684736 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
      "I0609 18:15:06.391765 139630267684736 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n",
      "I0609 18:15:06.393218 139630267684736 efficientnet_model.py:147] round_filter input=32 output=56\n",
      "I0609 18:15:06.406205 139630267684736 efficientnet_model.py:147] round_filter input=32 output=56\n",
      "I0609 18:15:06.406315 139630267684736 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0609 18:15:06.563778 139630267684736 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0609 18:15:06.563913 139630267684736 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0609 18:15:06.963034 139630267684736 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0609 18:15:06.963220 139630267684736 efficientnet_model.py:147] round_filter input=40 output=72\n",
      "I0609 18:15:07.357117 139630267684736 efficientnet_model.py:147] round_filter input=40 output=72\n",
      "I0609 18:15:07.357282 139630267684736 efficientnet_model.py:147] round_filter input=80 output=144\n",
      "I0609 18:15:07.888036 139630267684736 efficientnet_model.py:147] round_filter input=80 output=144\n",
      "I0609 18:15:07.888236 139630267684736 efficientnet_model.py:147] round_filter input=112 output=200\n",
      "I0609 18:15:08.594316 139630267684736 efficientnet_model.py:147] round_filter input=112 output=200\n",
      "I0609 18:15:08.594491 139630267684736 efficientnet_model.py:147] round_filter input=192 output=344\n",
      "I0609 18:15:09.305868 139630267684736 efficientnet_model.py:147] round_filter input=192 output=344\n",
      "I0609 18:15:09.306042 139630267684736 efficientnet_model.py:147] round_filter input=320 output=576\n",
      "I0609 18:15:09.499627 139630267684736 efficientnet_model.py:147] round_filter input=1280 output=2304\n",
      "I0609 18:15:09.529373 139630267684736 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0609 18:15:09.626858 139630267684736 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
      "I0609 18:15:09.627034 139630267684736 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
      "I0609 18:15:09.627136 139630267684736 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n",
      "I0609 18:15:09.629399 139630267684736 efficientnet_model.py:147] round_filter input=32 output=64\n",
      "I0609 18:15:09.643968 139630267684736 efficientnet_model.py:147] round_filter input=32 output=64\n",
      "I0609 18:15:09.644078 139630267684736 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0609 18:15:09.847490 139630267684736 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0609 18:15:09.847644 139630267684736 efficientnet_model.py:147] round_filter input=24 output=48\n",
      "I0609 18:15:10.299434 139630267684736 efficientnet_model.py:147] round_filter input=24 output=48\n",
      "I0609 18:15:10.299613 139630267684736 efficientnet_model.py:147] round_filter input=40 output=80\n",
      "I0609 18:15:10.775573 139630267684736 efficientnet_model.py:147] round_filter input=40 output=80\n",
      "I0609 18:15:10.775755 139630267684736 efficientnet_model.py:147] round_filter input=80 output=160\n",
      "I0609 18:15:11.444155 139630267684736 efficientnet_model.py:147] round_filter input=80 output=160\n",
      "I0609 18:15:11.444315 139630267684736 efficientnet_model.py:147] round_filter input=112 output=224\n",
      "I0609 18:15:12.312177 139630267684736 efficientnet_model.py:147] round_filter input=112 output=224\n",
      "I0609 18:15:12.312355 139630267684736 efficientnet_model.py:147] round_filter input=192 output=384\n",
      "I0609 18:15:13.151539 139630267684736 efficientnet_model.py:147] round_filter input=192 output=384\n",
      "I0609 18:15:13.151716 139630267684736 efficientnet_model.py:147] round_filter input=320 output=640\n",
      "I0609 18:15:13.425416 139630267684736 efficientnet_model.py:147] round_filter input=1280 output=2560\n",
      "I0609 18:15:13.461609 139630267684736 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 18.86s\n",
      "I0609 18:15:13.570816 139630267684736 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 18.86s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "I0609 18:15:13.577621 139630267684736 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "I0609 18:15:13.579197 139630267684736 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "I0609 18:15:13.579682 139630267684736 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "I0609 18:15:13.581092 139630267684736 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "[ RUN      ] ModelBuilderTF2Test.test_session\n",
      "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "I0609 18:15:13.582377 139630267684736 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "I0609 18:15:13.582796 139630267684736 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "I0609 18:15:13.583721 139630267684736 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "----------------------------------------------------------------------\n",
      "Ran 24 tests in 27.799s\n",
      "\n",
      "OK (skipped=1)\n"
     ]
    }
   ],
   "source": [
    "!python Tensorflow/models/research/object_detection/builders/model_builder_tf2_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vvOwtYLHIkjL",
    "outputId": "c2c9c51a-5288-4ddc-a97d-c0d60c3f5822",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.7/dist-packages (2.5.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied, skipping upgrade: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied, skipping upgrade: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.34.1)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied, skipping upgrade: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied, skipping upgrade: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied, skipping upgrade: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.12.4)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (57.0.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.8.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (0.4.4)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (0.6.1)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (3.3.4)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (2.25.1)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.30.0)\n",
      "Requirement already satisfied, skipping upgrade: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow) (4.0.1)\n",
      "Requirement already satisfied, skipping upgrade: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.2.2)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.7.2)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow) (3.4.1)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download generate_tfrecord.py file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dt0-PxxaGKgi"
   },
   "outputs": [],
   "source": [
    "!wget 'https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/_downloads/da4babe668a8afb093cc7776d7e630f3/generate_tfrecord.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_rjNBtwJMJxM"
   },
   "outputs": [],
   "source": [
    "!mv generate_tfrecord.py $SCRIPTS_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download the pretrained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lUFjw8lhNKLD",
    "outputId": "00fd9708-7bce-4ffe-af6c-4bfe9b994718"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-06-09 18:16:05--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.195.128, 2607:f8b0:400e:c09::80\n",
      "Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.195.128|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 90453990 (86M) [application/x-tar]\n",
      "Saving to: ‘ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz’\n",
      "\n",
      "ssd_mobilenet_v1_fp 100%[===================>]  86.26M   109MB/s    in 0.8s    \n",
      "\n",
      "2021-06-09 18:16:06 (109 MB/s) - ‘ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz’ saved [90453990/90453990]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "h_L6XCkDNXyk"
   },
   "outputs": [],
   "source": [
    "!mv ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz $PRETRAINED_MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JO1b6CbRNlst",
    "outputId": "6f0033b7-c9ed-4629-f87c-b4f60ca966be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/\n",
      "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/\n",
      "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
      "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/checkpoint\n",
      "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n",
      "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/pipeline.config\n",
      "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/saved_model/\n",
      "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/saved_model/saved_model.pb\n",
      "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/\n",
      "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
      "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "!cd Tensorflow/workspace/pre-trained-models/ && tar -zxvf ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4O4RS-dOQG-o"
   },
   "source": [
    "**OPTIONAL unziping of the images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1zJO9jjkPSnb",
    "outputId": "99b2c197-427e-4414-bc9f-36ad77c8f929"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow/workspace/images/train/\n",
      "Tensorflow/workspace/images/train/without_mask.1e5061c3-c94b-11eb-ab9a-68f728ea5740.jpg\n",
      "Tensorflow/workspace/images/train/without_mask.1e5061c3-c94b-11eb-ab9a-68f728ea5740.xml\n",
      "Tensorflow/workspace/images/train/without_mask.2454175f-c94b-11eb-acdb-68f728ea5740.jpg\n",
      "Tensorflow/workspace/images/train/without_mask.2454175f-c94b-11eb-acdb-68f728ea5740.xml\n",
      "Tensorflow/workspace/images/train/without_mask.8f7f27f1-c94b-11eb-8f19-68f728ea5740.jpg\n",
      "Tensorflow/workspace/images/train/without_mask.8f7f27f1-c94b-11eb-8f19-68f728ea5740.xml\n",
      "Tensorflow/workspace/images/train/without_mask.9281c3ce-c94b-11eb-80e6-68f728ea5740.jpg\n",
      "Tensorflow/workspace/images/train/without_mask.9281c3ce-c94b-11eb-80e6-68f728ea5740.xml\n",
      "Tensorflow/workspace/images/train/without_mask.9941202a-c6cb-11eb-a317-68f728ea5740.jpg\n",
      "Tensorflow/workspace/images/train/without_mask.9941202a-c6cb-11eb-a317-68f728ea5740.xml\n",
      "Tensorflow/workspace/images/train/without_mask.9f4ace46-c6cb-11eb-85c7-68f728ea5740.jpg\n",
      "Tensorflow/workspace/images/train/without_mask.9f4ace46-c6cb-11eb-85c7-68f728ea5740.xml\n",
      "Tensorflow/workspace/images/train/without_mask.a24d6a3e-c6cb-11eb-b3bf-68f728ea5740.jpg\n",
      "Tensorflow/workspace/images/train/without_mask.a24d6a3e-c6cb-11eb-b3bf-68f728ea5740.xml\n",
      "Tensorflow/workspace/images/train/with_mask.0ba18faa-c94b-11eb-9de8-68f728ea5740.jpg\n",
      "Tensorflow/workspace/images/train/with_mask.0ba18faa-c94b-11eb-9de8-68f728ea5740.xml\n",
      "Tensorflow/workspace/images/train/with_mask.0ea1c5f1-c94b-11eb-bf81-68f728ea5740.jpg\n",
      "Tensorflow/workspace/images/train/with_mask.0ea1c5f1-c94b-11eb-bf81-68f728ea5740.xml\n",
      "Tensorflow/workspace/images/train/with_mask.11a0d7bc-c94b-11eb-9be7-68f728ea5740.jpg\n",
      "Tensorflow/workspace/images/train/with_mask.11a0d7bc-c94b-11eb-9be7-68f728ea5740.xml\n",
      "Tensorflow/workspace/images/train/with_mask.79dcb37e-c94b-11eb-a634-68f728ea5740.jpg\n",
      "Tensorflow/workspace/images/train/with_mask.7cde241e-c94b-11eb-8bf0-68f728ea5740.jpg\n",
      "Tensorflow/workspace/images/train/with_mask.7cde241e-c94b-11eb-8bf0-68f728ea5740.xml\n",
      "Tensorflow/workspace/images/train/with_mask.7fded4a3-c94b-11eb-bc30-68f728ea5740.jpg\n",
      "Tensorflow/workspace/images/train/with_mask.7fded4a3-c94b-11eb-bc30-68f728ea5740.xml\n",
      "Tensorflow/workspace/images/train/with_mask.867efb9a-c6cb-11eb-982d-68f728ea5740.jpg\n",
      "Tensorflow/workspace/images/train/with_mask.867efb9a-c6cb-11eb-982d-68f728ea5740.xml\n",
      "Tensorflow/workspace/images/train/with_mask.8c96ccc8-c6cb-11eb-9449-68f728ea5740.jpg\n",
      "Tensorflow/workspace/images/train/with_mask.8c96ccc8-c6cb-11eb-9449-68f728ea5740.xml\n",
      "Tensorflow/workspace/images/train/with_mask.8f9bae67-c6cb-11eb-bf0f-68f728ea5740.jpg\n",
      "Tensorflow/workspace/images/train/with_mask.8f9bae67-c6cb-11eb-bf0f-68f728ea5740.xml\n",
      "Tensorflow/workspace/images/test/\n",
      "Tensorflow/workspace/images/test/without_mask.21513920-c94b-11eb-8608-68f728ea5740.jpg\n",
      "Tensorflow/workspace/images/test/without_mask.21513920-c94b-11eb-8608-68f728ea5740.xml\n",
      "Tensorflow/workspace/images/test/without_mask.8f7f27f1-c94b-11eb-8f19-68f728ea5740.jpg\n",
      "Tensorflow/workspace/images/test/without_mask.8f7f27f1-c94b-11eb-8f19-68f728ea5740.xml\n",
      "Tensorflow/workspace/images/test/without_mask.95841737-c94b-11eb-8814-68f728ea5740.jpg\n",
      "Tensorflow/workspace/images/test/without_mask.95841737-c94b-11eb-8814-68f728ea5740.xml\n",
      "Tensorflow/workspace/images/test/without_mask.9c45b1f5-c6cb-11eb-99ef-68f728ea5740.jpg\n",
      "Tensorflow/workspace/images/test/without_mask.9c45b1f5-c6cb-11eb-99ef-68f728ea5740.xml\n",
      "Tensorflow/workspace/images/test/without_mask.a55015c9-c6cb-11eb-85e9-68f728ea5740.jpg\n",
      "Tensorflow/workspace/images/test/without_mask.a55015c9-c6cb-11eb-85e9-68f728ea5740.xml\n",
      "Tensorflow/workspace/images/test/with_mask.79dcb37e-c94b-11eb-a634-68f728ea5740.jpg\n",
      "Tensorflow/workspace/images/test/with_mask.79dcb37e-c94b-11eb-a634-68f728ea5740.xml\n",
      "Tensorflow/workspace/images/test/with_mask.82df3723-c94b-11eb-a8a5-68f728ea5740.jpg\n",
      "Tensorflow/workspace/images/test/with_mask.82df3723-c94b-11eb-a8a5-68f728ea5740.xml\n",
      "Tensorflow/workspace/images/test/with_mask.8993f59e-c6cb-11eb-becf-68f728ea5740.jpg\n",
      "Tensorflow/workspace/images/test/with_mask.8993f59e-c6cb-11eb-becf-68f728ea5740.xml\n",
      "Tensorflow/workspace/images/test/with_mask.929ea940-c6cb-11eb-bd45-68f728ea5740.jpg\n",
      "Tensorflow/workspace/images/test/with_mask.929ea940-c6cb-11eb-bd45-68f728ea5740.xml\n"
     ]
    }
   ],
   "source": [
    "ARCHIVE_FILES = os.path.join(IMAGE_PATH, 'archive.tar.gz')\n",
    "if os.path.exists(ARCHIVE_FILES):\n",
    "  !tar -zxvf {ARCHIVE_FILES}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmP9wQgOQqQD"
   },
   "source": [
    "**Create lable map**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uXX_LVFNJCHA"
   },
   "outputs": [],
   "source": [
    "import object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "AIfOuRUAQ5dp"
   },
   "outputs": [],
   "source": [
    "labels = [{'name':'with_mask', 'id':1}, {'name':'without_mask', 'id':2}]\n",
    "\n",
    "with open(LABEL_MAP, 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pKzUPnFnRHPS",
    "outputId": "53e6960b-04f8-43b0-d0cc-ab3b7d514d14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: Tensorflow/workspace/annotations/train.record\n",
      "Successfully created the TFRecord file: Tensorflow/workspace/annotations/test.record\n"
     ]
    }
   ],
   "source": [
    "!python $TF_RECORD -x $IMAGE_TRAIN -l $LABEL_MAP -o $TRAIN_RECORD\n",
    "!python $TF_RECORD -x $IMAGE_TEST -l $LABEL_MAP -o $TEST_RECORD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12X5-yU7V4qK"
   },
   "source": [
    "**Create the custom pipeline config file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "HM2MP1BURaIS"
   },
   "outputs": [],
   "source": [
    "!cp $PIPELINE $CHECKPOINT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Lljxc6sDT1zy"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "521MJZnKUA8d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "A4t7dGyiT3tD"
   },
   "outputs": [],
   "source": [
    "config = config_util.get_configs_from_pipeline_file(CUSTOM_PIPELINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hraLuD47UVKG",
    "outputId": "660f95e8-79fd-4e40-e6a5-a918aff83714"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_config': metrics_set: \"coco_detection_metrics\"\n",
       " use_moving_averages: false\n",
       " batch_size: 1, 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " shuffle: false\n",
       " num_epochs: 1\n",
       " tf_record_input_reader {\n",
       "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " }, 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " shuffle: false\n",
       " num_epochs: 1\n",
       " tf_record_input_reader {\n",
       "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " }\n",
       " ], 'model': ssd {\n",
       "   num_classes: 90\n",
       "   image_resizer {\n",
       "     fixed_shape_resizer {\n",
       "       height: 640\n",
       "       width: 640\n",
       "     }\n",
       "   }\n",
       "   feature_extractor {\n",
       "     type: \"ssd_mobilenet_v1_fpn_keras\"\n",
       "     depth_multiplier: 1.0\n",
       "     min_depth: 16\n",
       "     conv_hyperparams {\n",
       "       regularizer {\n",
       "         l2_regularizer {\n",
       "           weight: 3.9999998989515007e-05\n",
       "         }\n",
       "       }\n",
       "       initializer {\n",
       "         random_normal_initializer {\n",
       "           mean: 0.0\n",
       "           stddev: 0.009999999776482582\n",
       "         }\n",
       "       }\n",
       "       activation: RELU_6\n",
       "       batch_norm {\n",
       "         decay: 0.996999979019165\n",
       "         scale: true\n",
       "         epsilon: 0.0010000000474974513\n",
       "       }\n",
       "     }\n",
       "     override_base_feature_extractor_hyperparams: true\n",
       "     fpn {\n",
       "       min_level: 3\n",
       "       max_level: 7\n",
       "     }\n",
       "   }\n",
       "   box_coder {\n",
       "     faster_rcnn_box_coder {\n",
       "       y_scale: 10.0\n",
       "       x_scale: 10.0\n",
       "       height_scale: 5.0\n",
       "       width_scale: 5.0\n",
       "     }\n",
       "   }\n",
       "   matcher {\n",
       "     argmax_matcher {\n",
       "       matched_threshold: 0.5\n",
       "       unmatched_threshold: 0.5\n",
       "       ignore_thresholds: false\n",
       "       negatives_lower_than_unmatched: true\n",
       "       force_match_for_each_row: true\n",
       "       use_matmul_gather: true\n",
       "     }\n",
       "   }\n",
       "   similarity_calculator {\n",
       "     iou_similarity {\n",
       "     }\n",
       "   }\n",
       "   box_predictor {\n",
       "     weight_shared_convolutional_box_predictor {\n",
       "       conv_hyperparams {\n",
       "         regularizer {\n",
       "           l2_regularizer {\n",
       "             weight: 3.9999998989515007e-05\n",
       "           }\n",
       "         }\n",
       "         initializer {\n",
       "           random_normal_initializer {\n",
       "             mean: 0.0\n",
       "             stddev: 0.009999999776482582\n",
       "           }\n",
       "         }\n",
       "         activation: RELU_6\n",
       "         batch_norm {\n",
       "           decay: 0.996999979019165\n",
       "           scale: true\n",
       "           epsilon: 0.0010000000474974513\n",
       "         }\n",
       "       }\n",
       "       depth: 256\n",
       "       num_layers_before_predictor: 4\n",
       "       kernel_size: 3\n",
       "       class_prediction_bias_init: -4.599999904632568\n",
       "     }\n",
       "   }\n",
       "   anchor_generator {\n",
       "     multiscale_anchor_generator {\n",
       "       min_level: 3\n",
       "       max_level: 7\n",
       "       anchor_scale: 4.0\n",
       "       aspect_ratios: 1.0\n",
       "       aspect_ratios: 2.0\n",
       "       aspect_ratios: 0.5\n",
       "       scales_per_octave: 2\n",
       "     }\n",
       "   }\n",
       "   post_processing {\n",
       "     batch_non_max_suppression {\n",
       "       score_threshold: 9.99999993922529e-09\n",
       "       iou_threshold: 0.6000000238418579\n",
       "       max_detections_per_class: 100\n",
       "       max_total_detections: 100\n",
       "       use_static_shapes: false\n",
       "     }\n",
       "     score_converter: SIGMOID\n",
       "   }\n",
       "   normalize_loss_by_num_matches: true\n",
       "   loss {\n",
       "     localization_loss {\n",
       "       weighted_smooth_l1 {\n",
       "       }\n",
       "     }\n",
       "     classification_loss {\n",
       "       weighted_sigmoid_focal {\n",
       "         gamma: 2.0\n",
       "         alpha: 0.25\n",
       "       }\n",
       "     }\n",
       "     classification_weight: 1.0\n",
       "     localization_weight: 1.0\n",
       "   }\n",
       "   encode_background_as_zeros: true\n",
       "   normalize_loc_loss_by_codesize: true\n",
       "   inplace_batchnorm_update: true\n",
       "   freeze_batchnorm: false\n",
       " }, 'train_config': batch_size: 64\n",
       " data_augmentation_options {\n",
       "   random_horizontal_flip {\n",
       "   }\n",
       " }\n",
       " data_augmentation_options {\n",
       "   random_crop_image {\n",
       "     min_object_covered: 0.0\n",
       "     min_aspect_ratio: 0.75\n",
       "     max_aspect_ratio: 3.0\n",
       "     min_area: 0.75\n",
       "     max_area: 1.0\n",
       "     overlap_thresh: 0.0\n",
       "   }\n",
       " }\n",
       " sync_replicas: true\n",
       " optimizer {\n",
       "   momentum_optimizer {\n",
       "     learning_rate {\n",
       "       cosine_decay_learning_rate {\n",
       "         learning_rate_base: 0.03999999910593033\n",
       "         total_steps: 25000\n",
       "         warmup_learning_rate: 0.013333000242710114\n",
       "         warmup_steps: 2000\n",
       "       }\n",
       "     }\n",
       "     momentum_optimizer_value: 0.8999999761581421\n",
       "   }\n",
       "   use_moving_average: false\n",
       " }\n",
       " fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
       " num_steps: 25000\n",
       " startup_delay_steps: 0.0\n",
       " replicas_to_aggregate: 8\n",
       " max_number_of_boxes: 100\n",
       " unpad_groundtruth_tensors: false\n",
       " fine_tune_checkpoint_type: \"classification\"\n",
       " fine_tune_checkpoint_version: V2, 'train_input_config': tf_record_input_reader {\n",
       "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
       " }}"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "YgYtQizlUWzs"
   },
   "outputs": [],
   "source": [
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(CUSTOM_PIPELINE, \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline_config)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wk1vxCNYeh1p",
    "outputId": "2adf979f-e505-4c44-996c-ca20772c1fae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_map.pbtxt  test.record  train.record\n"
     ]
    }
   ],
   "source": [
    "!cd Tensorflow/workspace/annotations && ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "N9oIJei_rF1-"
   },
   "outputs": [],
   "source": [
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "-HDxVoYMU0Ko"
   },
   "outputs": [],
   "source": [
    "pipeline_config.model.ssd.num_classes = len(labels)\n",
    "pipeline_config.train_config.batch_size = 4\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(PRETRAINED_MODEL_PATH, PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path= LABEL_MAP\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(ANNOTATION_PATH, 'train.record')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = LABEL_MAP\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(ANNOTATION_PATH, 'test.record')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "J0dDViLpgORV",
    "outputId": "703f809b-c17c-4939-85f3-75d4ef195e5c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Tensorflow/workspace/pre-trained-models/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0'"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(PRETRAINED_MODEL_PATH, 'ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8', 'checkpoint', 'ckpt-0')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ygcoHPIRWqVO"
   },
   "outputs": [],
   "source": [
    "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(CUSTOM_PIPELINE, \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_7CjQ7CWGoY"
   },
   "source": [
    "**Train Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Htuu0sFBtV7C"
   },
   "outputs": [],
   "source": [
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1fyrb699X_7t"
   },
   "outputs": [],
   "source": [
    "TRAINING_SCRIPT = os.path.join(APIMODEL_PATH, 'research', 'object_detection', 'model_main_tf2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "dTEYulFPYgmL"
   },
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=2000\".format(TRAINING_SCRIPT, CHECKPOINT_PATH,CUSTOM_PIPELINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L_f8gTKaX77L",
    "outputId": "b14f2f6f-8bb4-4713-f4fd-1c94698eecec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_ssd_mobnet --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --num_train_steps=2000\n"
     ]
    }
   ],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "573SEj7xVnkS",
    "outputId": "ba5b8503-5ede-40ff-e481-3fb1127a244d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-09 19:17:15.686298: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-06-09 19:17:17.524893: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-06-09 19:17:17.555283: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-09 19:17:17.556141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2021-06-09 19:17:17.556220: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-06-09 19:17:17.559314: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-06-09 19:17:17.559393: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-06-09 19:17:17.561235: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-06-09 19:17:17.561659: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-06-09 19:17:17.563512: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-06-09 19:17:17.564120: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-06-09 19:17:17.564294: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-06-09 19:17:17.564396: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-09 19:17:17.564977: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-09 19:17:17.565503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-06-09 19:17:17.566012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-09 19:17:17.566559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2021-06-09 19:17:17.566636: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-09 19:17:17.567201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-09 19:17:17.567711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-06-09 19:17:17.567757: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-06-09 19:17:18.153928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-06-09 19:17:18.153984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-06-09 19:17:18.154000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-06-09 19:17:18.154192: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-09 19:17:18.154805: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-09 19:17:18.155396: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-09 19:17:18.155912: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2021-06-09 19:17:18.155960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13837 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "W0609 19:17:18.157792 139761946953600 mirrored_strategy.py:379] Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "I0609 19:17:18.160507 139761946953600 mirrored_strategy.py:369] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 2000\n",
      "I0609 19:17:18.164086 139761946953600 config_util.py:552] Maybe overwriting train_steps: 2000\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0609 19:17:18.164221 139761946953600 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:558: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W0609 19:17:18.182783 139761946953600 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:558: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
      "I0609 19:17:18.186349 139761946953600 dataset_builder.py:163] Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
      "I0609 19:17:18.186505 139761946953600 dataset_builder.py:80] Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0609 19:17:18.186585 139761946953600 dataset_builder.py:81] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0609 19:17:18.186658 139761946953600 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "W0609 19:17:18.188629 139761946953600 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0609 19:17:18.205638 139761946953600 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0609 19:17:24.625022 139761946953600 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "W0609 19:17:27.521534 139761946953600 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0609 19:17:29.065935 139761946953600 deprecation.py:336] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "2021-06-09 19:17:31.164376: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-06-09 19:17:31.170713: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2199995000 Hz\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:435: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "2021-06-09 19:17:48.610253: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-06-09 19:17:49.054401: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8004\n",
      "2021-06-09 19:17:49.951558: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-06-09 19:17:50.432289: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0609 19:17:52.199645 139761946953600 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0609 19:17:52.200711 139761946953600 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0609 19:17:52.202593 139761946953600 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0609 19:17:52.203400 139761946953600 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0609 19:17:52.205297 139761946953600 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0609 19:17:52.206090 139761946953600 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0609 19:17:52.207912 139761946953600 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0609 19:17:52.208708 139761946953600 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0609 19:17:52.210549 139761946953600 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0609 19:17:52.211352 139761946953600 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:602: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W0609 19:17:52.812324 139758440736512 deprecation.py:534] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:602: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "INFO:tensorflow:Step 100 per-step time 0.696s\n",
      "I0609 19:19:02.026285 139761946953600 model_lib_v2.py:700] Step 100 per-step time 0.696s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.303163,\n",
      " 'Loss/localization_loss': 0.16717349,\n",
      " 'Loss/regularization_loss': 0.7766866,\n",
      " 'Loss/total_loss': 1.2470231,\n",
      " 'learning_rate': 0.014666351}\n",
      "I0609 19:19:02.026630 139761946953600 model_lib_v2.py:701] {'Loss/classification_loss': 0.303163,\n",
      " 'Loss/localization_loss': 0.16717349,\n",
      " 'Loss/regularization_loss': 0.7766866,\n",
      " 'Loss/total_loss': 1.2470231,\n",
      " 'learning_rate': 0.014666351}\n",
      "INFO:tensorflow:Step 200 per-step time 0.449s\n",
      "I0609 19:19:46.891125 139761946953600 model_lib_v2.py:700] Step 200 per-step time 0.449s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.24677835,\n",
      " 'Loss/localization_loss': 0.025755305,\n",
      " 'Loss/regularization_loss': 0.7758647,\n",
      " 'Loss/total_loss': 1.0483984,\n",
      " 'learning_rate': 0.0159997}\n",
      "I0609 19:19:46.891434 139761946953600 model_lib_v2.py:701] {'Loss/classification_loss': 0.24677835,\n",
      " 'Loss/localization_loss': 0.025755305,\n",
      " 'Loss/regularization_loss': 0.7758647,\n",
      " 'Loss/total_loss': 1.0483984,\n",
      " 'learning_rate': 0.0159997}\n",
      "INFO:tensorflow:Step 300 per-step time 0.439s\n",
      "I0609 19:20:30.802148 139761946953600 model_lib_v2.py:700] Step 300 per-step time 0.439s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.26865608,\n",
      " 'Loss/localization_loss': 0.02604057,\n",
      " 'Loss/regularization_loss': 0.77491,\n",
      " 'Loss/total_loss': 1.0696065,\n",
      " 'learning_rate': 0.01733305}\n",
      "I0609 19:20:30.802457 139761946953600 model_lib_v2.py:701] {'Loss/classification_loss': 0.26865608,\n",
      " 'Loss/localization_loss': 0.02604057,\n",
      " 'Loss/regularization_loss': 0.77491,\n",
      " 'Loss/total_loss': 1.0696065,\n",
      " 'learning_rate': 0.01733305}\n",
      "INFO:tensorflow:Step 400 per-step time 0.444s\n",
      "I0609 19:21:15.195752 139761946953600 model_lib_v2.py:700] Step 400 per-step time 0.444s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.32672438,\n",
      " 'Loss/localization_loss': 0.015879067,\n",
      " 'Loss/regularization_loss': 0.7738617,\n",
      " 'Loss/total_loss': 1.1164651,\n",
      " 'learning_rate': 0.0186664}\n",
      "I0609 19:21:15.196073 139761946953600 model_lib_v2.py:701] {'Loss/classification_loss': 0.32672438,\n",
      " 'Loss/localization_loss': 0.015879067,\n",
      " 'Loss/regularization_loss': 0.7738617,\n",
      " 'Loss/total_loss': 1.1164651,\n",
      " 'learning_rate': 0.0186664}\n",
      "INFO:tensorflow:Step 500 per-step time 0.439s\n",
      "I0609 19:21:59.134674 139761946953600 model_lib_v2.py:700] Step 500 per-step time 0.439s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.18997252,\n",
      " 'Loss/localization_loss': 0.011315837,\n",
      " 'Loss/regularization_loss': 0.7727464,\n",
      " 'Loss/total_loss': 0.9740347,\n",
      " 'learning_rate': 0.01999975}\n",
      "I0609 19:21:59.134974 139761946953600 model_lib_v2.py:701] {'Loss/classification_loss': 0.18997252,\n",
      " 'Loss/localization_loss': 0.011315837,\n",
      " 'Loss/regularization_loss': 0.7727464,\n",
      " 'Loss/total_loss': 0.9740347,\n",
      " 'learning_rate': 0.01999975}\n",
      "INFO:tensorflow:Step 600 per-step time 0.444s\n",
      "I0609 19:22:43.559951 139761946953600 model_lib_v2.py:700] Step 600 per-step time 0.444s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.218888,\n",
      " 'Loss/localization_loss': 0.012269307,\n",
      " 'Loss/regularization_loss': 0.7715822,\n",
      " 'Loss/total_loss': 1.0027394,\n",
      " 'learning_rate': 0.0213331}\n",
      "I0609 19:22:43.560272 139761946953600 model_lib_v2.py:701] {'Loss/classification_loss': 0.218888,\n",
      " 'Loss/localization_loss': 0.012269307,\n",
      " 'Loss/regularization_loss': 0.7715822,\n",
      " 'Loss/total_loss': 1.0027394,\n",
      " 'learning_rate': 0.0213331}\n",
      "INFO:tensorflow:Step 700 per-step time 0.442s\n",
      "I0609 19:23:27.712347 139761946953600 model_lib_v2.py:700] Step 700 per-step time 0.442s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.12375432,\n",
      " 'Loss/localization_loss': 0.016528716,\n",
      " 'Loss/regularization_loss': 0.7704533,\n",
      " 'Loss/total_loss': 0.9107363,\n",
      " 'learning_rate': 0.02266645}\n",
      "I0609 19:23:27.712648 139761946953600 model_lib_v2.py:701] {'Loss/classification_loss': 0.12375432,\n",
      " 'Loss/localization_loss': 0.016528716,\n",
      " 'Loss/regularization_loss': 0.7704533,\n",
      " 'Loss/total_loss': 0.9107363,\n",
      " 'learning_rate': 0.02266645}\n",
      "INFO:tensorflow:Step 800 per-step time 0.443s\n",
      "I0609 19:24:12.027890 139761946953600 model_lib_v2.py:700] Step 800 per-step time 0.443s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13250268,\n",
      " 'Loss/localization_loss': 0.009736963,\n",
      " 'Loss/regularization_loss': 0.7691396,\n",
      " 'Loss/total_loss': 0.9113792,\n",
      " 'learning_rate': 0.023999799}\n",
      "I0609 19:24:12.028202 139761946953600 model_lib_v2.py:701] {'Loss/classification_loss': 0.13250268,\n",
      " 'Loss/localization_loss': 0.009736963,\n",
      " 'Loss/regularization_loss': 0.7691396,\n",
      " 'Loss/total_loss': 0.9113792,\n",
      " 'learning_rate': 0.023999799}\n",
      "INFO:tensorflow:Step 900 per-step time 0.443s\n",
      "I0609 19:24:56.347100 139761946953600 model_lib_v2.py:700] Step 900 per-step time 0.443s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.10774404,\n",
      " 'Loss/localization_loss': 0.018008227,\n",
      " 'Loss/regularization_loss': 0.7677469,\n",
      " 'Loss/total_loss': 0.8934992,\n",
      " 'learning_rate': 0.025333151}\n",
      "I0609 19:24:56.347424 139761946953600 model_lib_v2.py:701] {'Loss/classification_loss': 0.10774404,\n",
      " 'Loss/localization_loss': 0.018008227,\n",
      " 'Loss/regularization_loss': 0.7677469,\n",
      " 'Loss/total_loss': 0.8934992,\n",
      " 'learning_rate': 0.025333151}\n",
      "INFO:tensorflow:Step 1000 per-step time 0.443s\n",
      "I0609 19:25:40.650782 139761946953600 model_lib_v2.py:700] Step 1000 per-step time 0.443s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.093007386,\n",
      " 'Loss/localization_loss': 0.01120734,\n",
      " 'Loss/regularization_loss': 0.7662555,\n",
      " 'Loss/total_loss': 0.8704702,\n",
      " 'learning_rate': 0.0266665}\n",
      "I0609 19:25:40.651094 139761946953600 model_lib_v2.py:701] {'Loss/classification_loss': 0.093007386,\n",
      " 'Loss/localization_loss': 0.01120734,\n",
      " 'Loss/regularization_loss': 0.7662555,\n",
      " 'Loss/total_loss': 0.8704702,\n",
      " 'learning_rate': 0.0266665}\n",
      "INFO:tensorflow:Step 1100 per-step time 0.446s\n",
      "I0609 19:26:25.261294 139761946953600 model_lib_v2.py:700] Step 1100 per-step time 0.446s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.06978429,\n",
      " 'Loss/localization_loss': 0.008530044,\n",
      " 'Loss/regularization_loss': 0.7647067,\n",
      " 'Loss/total_loss': 0.843021,\n",
      " 'learning_rate': 0.02799985}\n",
      "I0609 19:26:25.261601 139761946953600 model_lib_v2.py:701] {'Loss/classification_loss': 0.06978429,\n",
      " 'Loss/localization_loss': 0.008530044,\n",
      " 'Loss/regularization_loss': 0.7647067,\n",
      " 'Loss/total_loss': 0.843021,\n",
      " 'learning_rate': 0.02799985}\n",
      "INFO:tensorflow:Step 1200 per-step time 0.442s\n",
      "I0609 19:27:09.436354 139761946953600 model_lib_v2.py:700] Step 1200 per-step time 0.442s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.11582949,\n",
      " 'Loss/localization_loss': 0.017105902,\n",
      " 'Loss/regularization_loss': 0.76309985,\n",
      " 'Loss/total_loss': 0.8960352,\n",
      " 'learning_rate': 0.0293332}\n",
      "I0609 19:27:09.436667 139761946953600 model_lib_v2.py:701] {'Loss/classification_loss': 0.11582949,\n",
      " 'Loss/localization_loss': 0.017105902,\n",
      " 'Loss/regularization_loss': 0.76309985,\n",
      " 'Loss/total_loss': 0.8960352,\n",
      " 'learning_rate': 0.0293332}\n",
      "INFO:tensorflow:Step 1300 per-step time 0.443s\n",
      "I0609 19:27:53.718493 139761946953600 model_lib_v2.py:700] Step 1300 per-step time 0.443s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09454921,\n",
      " 'Loss/localization_loss': 0.007287176,\n",
      " 'Loss/regularization_loss': 0.7613696,\n",
      " 'Loss/total_loss': 0.86320597,\n",
      " 'learning_rate': 0.03066655}\n",
      "I0609 19:27:53.718805 139761946953600 model_lib_v2.py:701] {'Loss/classification_loss': 0.09454921,\n",
      " 'Loss/localization_loss': 0.007287176,\n",
      " 'Loss/regularization_loss': 0.7613696,\n",
      " 'Loss/total_loss': 0.86320597,\n",
      " 'learning_rate': 0.03066655}\n",
      "INFO:tensorflow:Step 1400 per-step time 0.441s\n",
      "I0609 19:28:37.861144 139761946953600 model_lib_v2.py:700] Step 1400 per-step time 0.441s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.061754514,\n",
      " 'Loss/localization_loss': 0.006308921,\n",
      " 'Loss/regularization_loss': 0.7595857,\n",
      " 'Loss/total_loss': 0.8276491,\n",
      " 'learning_rate': 0.0319999}\n",
      "I0609 19:28:37.861462 139761946953600 model_lib_v2.py:701] {'Loss/classification_loss': 0.061754514,\n",
      " 'Loss/localization_loss': 0.006308921,\n",
      " 'Loss/regularization_loss': 0.7595857,\n",
      " 'Loss/total_loss': 0.8276491,\n",
      " 'learning_rate': 0.0319999}\n",
      "INFO:tensorflow:Step 1500 per-step time 0.442s\n",
      "I0609 19:29:22.102854 139761946953600 model_lib_v2.py:700] Step 1500 per-step time 0.442s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07382547,\n",
      " 'Loss/localization_loss': 0.010419036,\n",
      " 'Loss/regularization_loss': 0.7577162,\n",
      " 'Loss/total_loss': 0.84196067,\n",
      " 'learning_rate': 0.03333325}\n",
      "I0609 19:29:22.103168 139761946953600 model_lib_v2.py:701] {'Loss/classification_loss': 0.07382547,\n",
      " 'Loss/localization_loss': 0.010419036,\n",
      " 'Loss/regularization_loss': 0.7577162,\n",
      " 'Loss/total_loss': 0.84196067,\n",
      " 'learning_rate': 0.03333325}\n",
      "INFO:tensorflow:Step 1600 per-step time 0.440s\n",
      "I0609 19:30:06.108810 139761946953600 model_lib_v2.py:700] Step 1600 per-step time 0.440s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.064927876,\n",
      " 'Loss/localization_loss': 0.0080573335,\n",
      " 'Loss/regularization_loss': 0.7557807,\n",
      " 'Loss/total_loss': 0.8287659,\n",
      " 'learning_rate': 0.034666598}\n",
      "I0609 19:30:06.109120 139761946953600 model_lib_v2.py:701] {'Loss/classification_loss': 0.064927876,\n",
      " 'Loss/localization_loss': 0.0080573335,\n",
      " 'Loss/regularization_loss': 0.7557807,\n",
      " 'Loss/total_loss': 0.8287659,\n",
      " 'learning_rate': 0.034666598}\n",
      "INFO:tensorflow:Step 1700 per-step time 0.442s\n",
      "I0609 19:30:50.324543 139761946953600 model_lib_v2.py:700] Step 1700 per-step time 0.442s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.071938075,\n",
      " 'Loss/localization_loss': 0.0055788695,\n",
      " 'Loss/regularization_loss': 0.75380576,\n",
      " 'Loss/total_loss': 0.8313227,\n",
      " 'learning_rate': 0.03599995}\n",
      "I0609 19:30:50.324845 139761946953600 model_lib_v2.py:701] {'Loss/classification_loss': 0.071938075,\n",
      " 'Loss/localization_loss': 0.0055788695,\n",
      " 'Loss/regularization_loss': 0.75380576,\n",
      " 'Loss/total_loss': 0.8313227,\n",
      " 'learning_rate': 0.03599995}\n",
      "INFO:tensorflow:Step 1800 per-step time 0.443s\n",
      "I0609 19:31:34.607359 139761946953600 model_lib_v2.py:700] Step 1800 per-step time 0.443s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.078850105,\n",
      " 'Loss/localization_loss': 0.0066679916,\n",
      " 'Loss/regularization_loss': 0.7517576,\n",
      " 'Loss/total_loss': 0.8372757,\n",
      " 'learning_rate': 0.037333302}\n",
      "I0609 19:31:34.607663 139761946953600 model_lib_v2.py:701] {'Loss/classification_loss': 0.078850105,\n",
      " 'Loss/localization_loss': 0.0066679916,\n",
      " 'Loss/regularization_loss': 0.7517576,\n",
      " 'Loss/total_loss': 0.8372757,\n",
      " 'learning_rate': 0.037333302}\n",
      "INFO:tensorflow:Step 1900 per-step time 0.443s\n",
      "I0609 19:32:18.866707 139761946953600 model_lib_v2.py:700] Step 1900 per-step time 0.443s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.06335151,\n",
      " 'Loss/localization_loss': 0.007520571,\n",
      " 'Loss/regularization_loss': 0.7496023,\n",
      " 'Loss/total_loss': 0.8204744,\n",
      " 'learning_rate': 0.03866665}\n",
      "I0609 19:32:18.867013 139761946953600 model_lib_v2.py:701] {'Loss/classification_loss': 0.06335151,\n",
      " 'Loss/localization_loss': 0.007520571,\n",
      " 'Loss/regularization_loss': 0.7496023,\n",
      " 'Loss/total_loss': 0.8204744,\n",
      " 'learning_rate': 0.03866665}\n",
      "INFO:tensorflow:Step 2000 per-step time 0.444s\n",
      "I0609 19:33:03.240357 139761946953600 model_lib_v2.py:700] Step 2000 per-step time 0.444s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.077173606,\n",
      " 'Loss/localization_loss': 0.0054971054,\n",
      " 'Loss/regularization_loss': 0.7473922,\n",
      " 'Loss/total_loss': 0.83006287,\n",
      " 'learning_rate': 0.04}\n",
      "I0609 19:33:03.240686 139761946953600 model_lib_v2.py:701] {'Loss/classification_loss': 0.077173606,\n",
      " 'Loss/localization_loss': 0.0054971054,\n",
      " 'Loss/regularization_loss': 0.7473922,\n",
      " 'Loss/total_loss': 0.83006287,\n",
      " 'learning_rate': 0.04}\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Ov-dVJkYb-nl"
   },
   "outputs": [],
   "source": [
    "!tar -czf models.tar.gz $CHECKPOINT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f2qoAZNV1eof",
    "outputId": "3f2c73a0-284a-475b-e1c4-1e3b66916d94"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-10 19:49:10.316193: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2021-06-10 19:49:10.316264: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "C:\\Users\\Namratha\\anaconda3\\envs\\FMD\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Namratha\\anaconda3\\envs\\FMD\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "C:\\Users\\Namratha\\anaconda3\\envs\\FMD\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "2021-06-10 19:49:22.844480: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found\n",
      "2021-06-10 19:49:22.844524: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-06-10 19:49:22.849446: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: DESKTOP-7SVMDA8\n",
      "2021-06-10 19:49:22.849580: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: DESKTOP-7SVMDA8\n",
      "2021-06-10 19:49:22.850931: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From C:\\Users\\Namratha\\anaconda3\\envs\\FMD\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:463: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "W0610 19:49:23.255861  2424 deprecation.py:596] From C:\\Users\\Namratha\\anaconda3\\envs\\FMD\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:463: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x000002E21EBE0A30>, because it is not built.\n",
      "W0610 19:50:04.526994  2424 save_impl.py:76] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x000002E21EBE0A30>, because it is not built.\n",
      "2021-06-10 19:50:22.481624: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "W0610 19:51:05.726614  2424 save.py:238] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxPredictor_layer_call_fn while saving (showing 5 of 520). These functions will not be directly callable after loading.\n",
      "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n",
      "W0610 19:51:38.740794  2424 save.py:1239] FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n",
      "INFO:tensorflow:Assets written to: Tensorflow/workspace/models/exported-models/my_model\\saved_model\\assets\n",
      "I0610 19:51:40.154151  2424 builder_impl.py:774] Assets written to: Tensorflow/workspace/models/exported-models/my_model\\saved_model\\assets\n",
      "INFO:tensorflow:Writing pipeline config file to Tensorflow/workspace/models/exported-models/my_model\\pipeline.config\n",
      "I0610 19:51:54.386705  2424 config_util.py:253] Writing pipeline config file to Tensorflow/workspace/models/exported-models/my_model\\pipeline.config\n"
     ]
    }
   ],
   "source": [
    "!python Tensorflow/models/research/object_detection/exporter_main_v2.py --input_type image_tensor --pipeline_config_path Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config  --trained_checkpoint_dir Tensorflow/workspace/models/my_ssd_mobnet/ --output_directory Tensorflow/workspace/models/exported-models/my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Traning_Custom_Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
